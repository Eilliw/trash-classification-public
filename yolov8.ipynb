{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start\n",
    "\n",
    "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!killall python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing cuDNN & pytorch - Setting environmental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import platform\n",
    "print(platform.system())\n",
    "if platform.system()== \"Windows\":\n",
    "    %pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "else:\n",
    "    print('running on linux')\n",
    "    %pip install torch torchvision torchaudio\n",
    "    %pip install torch torchvision torchaudio -U\n",
    "%pip install comet_ml --quiet\n",
    "# pip install comet_ml\n",
    "#%env CUDA_PATH = \"E:\\software\\cuDNN\\cudnn-windows-x86_64-8.9.5.29_cuda12-archive\"\n",
    "import torch\n",
    "import torchvision\n",
    "print(torch.cuda.__path__)\n",
    "print(torch.version.cuda)\n",
    "\n",
    "#torch.from_numpy(boxes.detach().cpu().numpy())\n",
    "\n",
    "\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install YOLOv8\n",
    "\n",
    "⚠️ YOLOv8 is still under heavy development. Breaking changes are being introduced almost weekly. We strive to make our YOLOv8 notebooks work with the latest version of the library. Last tests took place on **27.01.2023** with version **YOLOv8.0.20**.\n",
    "\n",
    "If you notice that our notebook behaves incorrectly - especially if you experience errors that prevent you from going through the tutorial - don't hesitate! Let us know and open an [issue](https://github.com/roboflow/notebooks/issues) on the Roboflow Notebooks repository.\n",
    "\n",
    "YOLOv8 can be installed in two ways - from the source and via pip. This is because it is the first iteration of YOLO to have an official package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pip install method (recommended)\n",
    "\n",
    "#%pip install ultralytics==8.0.20\n",
    "#%pip  install ultralytics\n",
    "%pip install ultralytics\n",
    "\n",
    "from IPython import display\n",
    "#display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()\n",
    "\n",
    "import torch\n",
    "GPUS_AVALIBLE = torch.cuda.device_count()\n",
    "print(GPUS_AVALIBLE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Git clone method (for development)\n",
    "\n",
    "# %cd {HOME}\n",
    "# !git clone github.com/ultralytics/ultralytics\n",
    "# %cd {HOME}/ultralytics\n",
    "# !pip install -e .\n",
    "\n",
    "# from IPython import display\n",
    "# display.clear_output()\n",
    "\n",
    "# import ultralytics\n",
    "# ultralytics.checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to train, validate or run inference on models and don't need to make any modifications to the code, using YOLO command line interface is the easiest way to get started. Read more about CLI in [Ultralytics YOLO Docs](https://docs.ultralytics.com/usage/cli/).\n",
    "\n",
    "```\n",
    "yolo task=detect    mode=train    model=yolov8n.yaml      args...\n",
    "          classify       predict        yolov8n-cls.yaml  args...\n",
    "          segment        val            yolov8n-seg.yaml  args...\n",
    "                         export         yolov8n.pt        format=onnx  args...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%mkdir {HOME}\n",
    "%cd {HOME}\n",
    "\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv(\".env\")\n",
    "\n",
    "ROBOFLOW_API_KEY = os.getenv(\"ROBOFLOW_API_KEY\")\n",
    "\n",
    "%pip install roboflow --quiet\n",
    "#%pip install ultralytics==8.0.134\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
    "project = rf.workspace(\"trashclassification-tayqe\").project(\"trash-xvysc\")\n",
    "dataset = project.version(2).download(\"yolov8\",overwrite=False, location=f\"{HOME}//datasets\")\n",
    "dataset_version = dataset.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run scripts/train.py\n",
    "\n",
    "#CLASSIFY requirements\n",
    "\"\"\"\n",
    "imgsz=224\n",
    "task=classify\n",
    "dataset must be heiracel or clip\n",
    "dataset objects must be isolated for classification\n",
    "\"\"\"\n",
    "\n",
    "from scripts.train import YOLO_Trainer\n",
    "\n",
    "model = \"yolov8x-cls.pt\"\n",
    "clean_model =  model.removesuffix(\".pt\")\n",
    "\n",
    "task = \"classify\"\n",
    "imgsz = 224\n",
    "\n",
    "cstm_class = YOLO_Trainer(model=model, task=task, classify_project_id=\"trash-vs-recycling-pi-cam\", clearml_project_name=\"rpi-trash-classification\")\n",
    "\n",
    "cstm_class.train(\"trash-classification\",task=task,bs=64,name=clean_model, exist_ok=True, export='torchscript',  imgsz = 224, cache=True, epochs=50)\n",
    "#cstm_class.model.benchmark(data=cstm_class.dataset.location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "#pytorchmodel = torch.jit.script(\"exports/best.pt\")\n",
    "\n",
    "model = YOLO(\"exports/pytorchtotrt.pt\")\n",
    "model.export(format=\"onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from torchinfo import summary\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "\n",
    "#model = YOLO(\"trash-classification/yolov8m/weights/best.pt\")\n",
    "#print(model.info(detailed=True))\n",
    "\n",
    "#model = YOLO(\"trash-classification/yolov8l-cls/weights/best.pt\")\n",
    "model = YOLO(\"yolov8x-cls\")\n",
    "model.export(format=\"torchscript\")\n",
    "#model.benchmark(data=\"datasets/trash-2/clip\")\n",
    "# pt_model = YOLO(\"trash-classification/yolov8m/weights/best.pt\")\n",
    "# print(pt_model.info(detailed=True))\n",
    "# print(pt_model)\n",
    "#print(vgg)\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(HOME)\n",
    "%ls {HOME}\\\\runs\\\\detect\\\\train31\\\\\n",
    "#%ls runs\\detect\\train31\\\n",
    "\n",
    "curr_train_path = HOME+\"/runs/detect/train39\"\n",
    "curr_train = os.path.normpath(curr_train_path)\n",
    "print(curr_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {HOME}\n",
    "from IPython.display import Image\n",
    "#Image(filename=f'{HOME}/runs/detect/train/confusion_matrix.png', width=600)\n",
    "Image(filename=f\"{curr_train}/confusion_matrix.png\",width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {HOME}\n",
    "Image(filename=f'{curr_train}/results.png', width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {HOME}\n",
    "valbatch0 = Image(filename=f'{curr_train}/val_batch0_pred.jpg', width=600)\n",
    "valbatch1 = Image(filename=f'{curr_train}/val_batch1_pred.jpg', width=600)\n",
    "valbatch2 = Image(filename=f'{curr_train}/val_batch2_pred.jpg', width=600)\n",
    "display.display(valbatch0,valbatch1,valbatch2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
